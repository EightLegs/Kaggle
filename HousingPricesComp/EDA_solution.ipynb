{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#19600.61185 submission score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, cross_validate, RandomizedSearchCV\n",
    "\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NA_Columns_Manage(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].isna().any():\n",
    "            if df[col].nunique() < 20:\n",
    "                df[col]=df[col].fillna(-1)\n",
    "            else:\n",
    "                df[col] = df[col].fillna(int(df[col].mean()))\n",
    "    return df\n",
    "\n",
    "def Object_Columns_Manage(train_df, test_df):\n",
    "    categorical_columns = [cname for cname in train_df.columns if train_df[cname].dtype in ['object']] \n",
    "    train_df = pd.get_dummies(train_df, columns=categorical_columns)\n",
    "    test_df = pd.get_dummies(test_df, columns=categorical_columns)\n",
    "    for cname in train_df.columns:\n",
    "        if cname not in test_df.columns:\n",
    "            train_df.drop(cname, axis=1, inplace=True)\n",
    "    for cname in test_df.columns:\n",
    "        if cname not in train_df.columns:\n",
    "            test_df.drop(cname, axis=1, inplace=True)\n",
    "    return train_df, test_df\n",
    "\n",
    "def Correlation_Manage(train_df, test_df):\n",
    "    pca = PCA(n_components=70)\n",
    "    train_df = pd.DataFrame(pca.fit_transform(train_df))\n",
    "    test_df = pd.DataFrame(pca.transform(test_df))\n",
    "    return train_df, test_df\n",
    "\n",
    "def Make_Sub_File(model, test_df, test_Id):\n",
    "    predictions = model.predict(test_df)\n",
    "    output = pd.DataFrame({'Id': test_Id,\n",
    "                           'SalePrice': predictions})\n",
    "    output.to_csv('Output//EDA_solution_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('Input//train.csv')\n",
    "test_df = pd.read_csv('Input//test.csv')\n",
    "\n",
    "Y = train_df['SalePrice']\n",
    "train_df.drop(['SalePrice', 'Id'], axis = 1, inplace=True)\n",
    "test_Id = test_df['Id']\n",
    "test_df.drop(['Id'], axis = 1, inplace=True)\n",
    "\n",
    "train_df = NA_Columns_Manage(train_df)\n",
    "test_df = NA_Columns_Manage(test_df)\n",
    "\n",
    "train_df,test_df = Object_Columns_Manage(train_df,test_df)\n",
    "train_df,test_df = Correlation_Manage(train_df,test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model1 = linear_model.Lasso()\n",
    "\n",
    "parameters1 = {'alpha': np.arange(0.7,1, 0.1),\n",
    "             'max_iter': np.arange(1000, 1500, 100)}\n",
    "\n",
    "X_train_part, X_valid_part, y_train_part, y_valid_part = train_test_split(train_df, Y, train_size = 0.8, test_size = 0.2, random_state = 8)\n",
    "\n",
    "random_search1 = RandomizedSearchCV(model1, parameters1,cv=10,n_iter=10, random_state=0, n_jobs = -1, verbose = 0)\n",
    "random_search1.fit(X_train_part, y_train_part)\n",
    "#test_preds = random_search.predict(X_valid_part)\n",
    "print(cross_val_score(random_search1, X_valid_part, y_valid_part,scoring='neg_mean_squared_error', cv=10, verbose=0).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model2 = XGBRegressor(random_state=8, n_jobs =-1)\n",
    "parameters2 = {'booster': ['gbtree','dart','gblinear'], \n",
    "              'num_feature':np.arange(10,80,5), \n",
    "              'max_depth':np.arange(6,50, 5), \n",
    "              'n_estimators':np.arange(100,2000,100),\n",
    "              'learning_rate':np.arange(0.01, 0.1, 0.01),\n",
    "              'reg_alpha' : np.arange(0.01, 5),\n",
    "              'reg_lambda' : np.arange(0.01, 5),\n",
    "              'gamma' : np.arange(0.01,5)}\n",
    "\n",
    "X_train_part, X_valid_part, y_train_part, y_valid_part = train_test_split(train_df, Y, train_size = 0.8, test_size = 0.2, random_state = 8)\n",
    "\n",
    "random_search2 = RandomizedSearchCV(model2, parameters2,cv=10,n_iter=10, random_state=0, n_jobs = -1, verbose = 0)\n",
    "random_search2.fit(X_train_part, y_train_part)\n",
    "#test_preds = random_search.predict(X_valid_part)\n",
    "print(cross_val_score(random_search2, X_valid_part, y_valid_part,scoring='neg_mean_squared_error', cv=10, verbose=0).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = random_search2.predict(train_df)\n",
    "r2_score(Y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Make_Sub_File(random_search2, test_df, test_Id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Дальше идет черновик\n",
    "\n",
    "-1742802409\n",
    "-1300000000\n",
    "-1316463301\n",
    "-1260926092\n",
    "-1328533615\n",
    "-1696231705 -200 iter\n",
    "\n",
    "categorical_columns = [cname for cname in train_df.columns if train_df[cname].nunique() < 20\n",
    "                            and train_df[cname].dtype in ['object', 'str']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_df.shape[1], train_df.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    corr_matrix = df.corr().abs()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > 0.6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(100,80))\n",
    "sns.heatmap(train_df.isnull(), cbar=False)\n",
    "plt.figure(figsize=(100,80))\n",
    "sns.heatmap(test_df.isnull(), cbar=False)\n",
    "\n",
    "for column in numerical_columns:\n",
    "    plt.figure(figsize=(5,5))\n",
    "    sns.scatterplot(data=train_df, x='SalePrice', y=column)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
